const airflowClient = require('./airflowClient');
const kafkaProducer = require('./kafkaProducer');
const cacheService = require('./cacheService');
const { Sentry } = require('../config/sentry');

/**
 * ë¶„ì„ ì„œë¹„ìŠ¤
 * Airflow DAG íŠ¸ë¦¬ê±° ë° ë¶„ì„ ìš”ì²­ ê´€ë¦¬
 */
class AnalysisService {
  constructor() {
    this.analysisCache = new Map(); // ì§„í–‰ ì¤‘ì¸ ë¶„ì„ ìš”ì²­ ìºì‹œ
  }

  /**
   * ë‹¨ì¼ ìƒí’ˆ ë¶„ì„ ìš”ì²­
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.productId - ìƒí’ˆ ID
   * @param {string} params.productUrl - ìƒí’ˆ URL
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestSingleProductAnalysis(params) {
    try {
      const { productId, productUrl, userId } = params;
      
      console.log(`ğŸ” Starting single product analysis request:`, {
        productId,
        userId,
        hasUrl: !!productUrl,
      });

      // ì¤‘ë³µ ìš”ì²­ ì²´í¬
      const cacheKey = `analysis:single:${productId}:${userId}`;
      const existingRequest = await cacheService.get(cacheKey);
      
      if (existingRequest) {
        console.log(`âš¡ Found existing analysis request for product ${productId}`);
        return {
          status: 'in_progress',
          dagRunId: existingRequest.dagRunId,
          message: 'Analysis already in progress',
          cached: true,
        };
      }

      // Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerSingleProductAnalysis({
        productId,
        productUrl,
        userId,
      });

      // ìš”ì²­ ì •ë³´ ìºì‹œì— ì €ì¥ (30ë¶„ TTL)
      const requestInfo = {
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        productId,
        userId,
        status: 'triggered',
        createdAt: new Date().toISOString(),
      };
      
      await cacheService.set(cacheKey, requestInfo, 1800); // 30ë¶„

      // Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
      await kafkaProducer.sendMessage('analysis-requests', {
        type: 'single_product_analysis_started',
        dagRunId: dagRun.dagRunId,
        productId,
        userId,
        timestamp: new Date().toISOString(),
      });

      console.log(`âœ… Single product analysis triggered successfully:`, {
        dagRunId: dagRun.dagRunId,
        productId,
      });

      return {
        status: 'triggered',
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request single product analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'single_product',
          productId: params.productId,
          userId: params.userId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * ë‹¤ì¤‘ ìƒí’ˆ ë¶„ì„ ìš”ì²­ (ê²€ìƒ‰ì–´ ê¸°ë°˜)
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.searchQuery - ê²€ìƒ‰ì–´
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @param {number} params.maxProducts - ìµœëŒ€ ìƒí’ˆ ìˆ˜
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestMultiProductAnalysis(params) {
    try {
      const { searchQuery, userId, maxProducts = 10 } = params;
      
      console.log(`ğŸ” Starting multi product analysis request:`, {
        searchQuery,
        userId,
        maxProducts,
      });

      // ì¤‘ë³µ ìš”ì²­ ì²´í¬
      const cacheKey = `analysis:multi:${searchQuery}:${userId}`;
      const existingRequest = await cacheService.get(cacheKey);
      
      if (existingRequest) {
        console.log(`âš¡ Found existing analysis request for search "${searchQuery}"`);
        return {
          status: 'in_progress',
          dagRunId: existingRequest.dagRunId,
          message: 'Analysis already in progress',
          cached: true,
        };
      }

      // Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerMultiProductAnalysis({
        searchQuery,
        userId,
        maxProducts,
      });

      // ìš”ì²­ ì •ë³´ ìºì‹œì— ì €ì¥ (30ë¶„ TTL)
      const requestInfo = {
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        searchQuery,
        userId,
        maxProducts,
        status: 'triggered',
        createdAt: new Date().toISOString(),
      };
      
      await cacheService.set(cacheKey, requestInfo, 1800); // 30ë¶„

      // Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
      await kafkaProducer.sendMessage('analysis-requests', {
        type: 'multi_product_analysis_started',
        dagRunId: dagRun.dagRunId,
        searchQuery,
        userId,
        maxProducts,
        timestamp: new Date().toISOString(),
      });

      console.log(`âœ… Multi product analysis triggered successfully:`, {
        dagRunId: dagRun.dagRunId,
        searchQuery,
      });

      return {
        status: 'triggered',
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request multi product analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'multi_product',
          searchQuery: params.searchQuery,
          userId: params.userId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * ê´€ì‹¬ ìƒí’ˆ ë°°ì¹˜ ë¶„ì„ ìš”ì²­
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @param {Array} params.productIds - ê´€ì‹¬ ìƒí’ˆ ID ëª©ë¡
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestWatchlistAnalysis(params) {
    try {
      const { userId, productIds } = params;
      
      console.log(`ğŸ” Starting watchlist analysis request:`, {
        userId,
        productCount: productIds.length,
      });

      // ì¤‘ë³µ ìš”ì²­ ì²´í¬
      const cacheKey = `analysis:watchlist:${userId}`;
      const existingRequest = await cacheService.get(cacheKey);
      
      if (existingRequest) {
        console.log(`âš¡ Found existing watchlist analysis request for user ${userId}`);
        return {
          status: 'in_progress',
          dagRunId: existingRequest.dagRunId,
          message: 'Watchlist analysis already in progress',
          cached: true,
        };
      }

      // Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerWatchlistAnalysis({
        userId,
        productIds,
      });

      // ìš”ì²­ ì •ë³´ ìºì‹œì— ì €ì¥ (1ì‹œê°„ TTL)
      const requestInfo = {
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        userId,
        productIds,
        status: 'triggered',
        createdAt: new Date().toISOString(),
      };
      
      await cacheService.set(cacheKey, requestInfo, 3600); // 1ì‹œê°„

      // Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
      await kafkaProducer.sendMessage('analysis-requests', {
        type: 'watchlist_analysis_started',
        dagRunId: dagRun.dagRunId,
        userId,
        productIds,
        timestamp: new Date().toISOString(),
      });

      console.log(`âœ… Watchlist analysis triggered successfully:`, {
        dagRunId: dagRun.dagRunId,
        userId,
        productCount: productIds.length,
      });

      return {
        status: 'triggered',
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Watchlist analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request watchlist analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'watchlist',
          userId: params.userId,
          productCount: params.productIds.length,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * ë¶„ì„ ìƒíƒœ ì¡°íšŒ
   * @param {string} dagId - DAG ID
   * @param {string} dagRunId - DAG Run ID
   * @returns {Promise<Object>} ë¶„ì„ ìƒíƒœ ì •ë³´
   */
  async getAnalysisStatus(dagId, dagRunId) {
    try {
      console.log(`ğŸ” Getting analysis status: ${dagId}/${dagRunId}`);

      // ìºì‹œì—ì„œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
      const cacheKey = `status:${dagId}:${dagRunId}`;
      const cachedStatus = await cacheService.get(cacheKey);

      // Airflowì—ì„œ ìµœì‹  ìƒíƒœ ì¡°íšŒ
      const dagRunStatus = await airflowClient.getDagRunStatus(dagId, dagRunId);
      const tasks = await airflowClient.getDagRunTasks(dagId, dagRunId);

      const result = {
        dagId,
        dagRunId,
        state: dagRunStatus.state,
        executionDate: dagRunStatus.executionDate,
        startDate: dagRunStatus.startDate,
        endDate: dagRunStatus.endDate,
        tasks: tasks,
        progress: this.calculateProgress(tasks),
        cached: !!cachedStatus,
      };

      // ìƒíƒœ ì •ë³´ ìºì‹œ (5ë¶„ TTL)
      await cacheService.set(cacheKey, result, 300);

      console.log(`ğŸ“Š Analysis status retrieved:`, {
        dagRunId,
        state: result.state,
        progress: result.progress,
      });

      return result;

    } catch (error) {
      console.error('âŒ Failed to get analysis status:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_status_check_failed', true);
        scope.setContext('analysis_status_check', {
          dagId,
          dagRunId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * íƒœìŠ¤í¬ ì§„í–‰ë¥  ê³„ì‚°
   * @param {Array} tasks - íƒœìŠ¤í¬ ëª©ë¡
   * @returns {Object} ì§„í–‰ë¥  ì •ë³´
   */
  calculateProgress(tasks) {
    const totalTasks = tasks.length;
    const completedTasks = tasks.filter(task => task.state === 'success').length;
    const failedTasks = tasks.filter(task => task.state === 'failed').length;
    const runningTasks = tasks.filter(task => task.state === 'running').length;

    return {
      total: totalTasks,
      completed: completedTasks,
      failed: failedTasks,
      running: runningTasks,
      percentage: totalTasks > 0 ? Math.round((completedTasks / totalTasks) * 100) : 0,
    };
  }

  /**
   * í™œì„± ë¶„ì„ ëª©ë¡ ì¡°íšŒ
   * @param {string} userId - ì‚¬ìš©ì ID
   * @returns {Promise<Array>} í™œì„± ë¶„ì„ ëª©ë¡
   */
  async getActiveAnalyses(userId) {
    try {
      console.log(`ğŸ” Getting active analyses for user: ${userId}`);

      // ìºì‹œì—ì„œ ì‚¬ìš©ìì˜ í™œì„± ë¶„ì„ ëª©ë¡ ì¡°íšŒ
      const cachePattern = `analysis:*:*:${userId}`;
      const activeAnalyses = [];

      // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Redis SCANì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë³„ë„ ì¸ë±ìŠ¤ ê´€ë¦¬ í•„ìš”
      // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ êµ¬í˜„

      console.log(`ğŸ“‹ Found ${activeAnalyses.length} active analyses for user ${userId}`);
      
      return activeAnalyses;

    } catch (error) {
      console.error('âŒ Failed to get active analyses:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('active_analyses_check_failed', true);
        scope.setContext('active_analyses_check', { userId });
        Sentry.captureException(error);
      });

      throw error;
    }
  }
}

module.exports = new AnalysisService();